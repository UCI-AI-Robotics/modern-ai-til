{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Large Language Model (LLM) from Scratch\n",
    "\n",
    "#### References\n",
    "- [Andrej Karpathy's YouTube Channel](https://www.youtube.com/andrejkarpathy)\n",
    "- [Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\n",
    "- [Om-Alve/smolGPT GitHub](https://github.com/Om-Alve/smolGPT)\n",
    "- Transformer Paper – [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "- OpenAI GPT2 Paper - [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env Setup\n",
    "\n",
    "Install compatible pytorch according to your GPU/Cuda version.\n",
    "\n",
    "```\n",
    "pip install tiktoken\n",
    "pip install transformers\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu116\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "*This learning material is designed to help you study the core concepts of LLMs through simple hands-on exercises on a personal computer. It summarizes and organizes well-known educational and academic resources to make learning easier. Please note that the coding style and scope of application may differ from other implementations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전체 과정 요약\n",
    "\n",
    "LLM 기반 AI 에이전트를 만들때는 핵심이 되는 LLM이 필요한데요, LLM을 바닥부터 만드는 경우 보다는 공개되어 있는 LLM 모델들을 가져다가 나의 용도에 맞도록 다듬어서 사용하는 것이 일반적입니다. 다만, 최근에는 LLM을 바닥부터 만드는 기술에 대한 진입장벽이 낮아지고 있어서 회사별로 필요한 LLM을 바닥부터 각자 만들어 사용하게 될 가능성도 높아지고 있습니다.\n",
    "\n",
    "LLM을 만들 때는 \n",
    "\n",
    "1. 사전훈련(pretraining)으로 일반적인 언어 능력을 가르친 후에 \n",
    "2. 미세조정(fine tuning) 단계에서 특정 업무에 적응\n",
    "\n",
    "시키는 것이 기본이 됩니다. 여기에 \n",
    "\n",
    "3. 데이터베이스(+인터넷) 검색 기능을 추가\n",
    "\n",
    "하면 지식의 범위와 정확성을 높일 수 있습니다. 사람이 생각을 거듭하여 더 깊이있는 결론을 이끌어 내듯이 LLM도 \n",
    "\n",
    "4. 내부적으로 질의를 반복하여 더 좋은 결론을 도출\n",
    "\n",
    "하도록 만들 수 있습니다.\n",
    "\n",
    "여기서는 LLM의 기본 원리를 이해하기 위해서 사전훈련 과정을 바닥부터 진행해보겠습니다. 훈련 과정의 큰 틀은 일반적인 머신러닝 절차를 따릅니다.\n",
    "\n",
    "1. 훈련 데이터 준비\n",
    "1. 데이터 로더 정의\n",
    "1. 모델 정의\n",
    "1. 훈련\n",
    "1. 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련 데이터 준비\n",
    "\n",
    "준비한 텍스트 파일을 읽어 들여서 정리한 후에 앞에 cleaned_가 붙은 파일 이름으로 정리합니다.\n",
    "> 예시) alice.txt &rarr; cleaned_alice.txt\n",
    "\n",
    "- 캐글 해리포터 책 - [Harry Potter Books](https://www.kaggle.com/datasets/shubhammaindola/harry-potter-books?select=02+Harry+Potter+and+the+Chamber+of+Secrets.txt)\n",
    "- 캐글 앨리스 책 - [alice.txt](https://www.kaggle.com/datasets/leelatte/alicetxt)\n",
    "- 훈련 데이터나 가중치는 제가 배포하지 않습니다. 직접 다운받거나 준비하셔야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_02 Harry Potter and the Chamber of Secrets.txt 488771 characters\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        book_text = file.read()\n",
    "\n",
    "    cleaned_text = re.sub(r'\\n+', ' ', book_text) # 줄바꿈을 빈칸으로 변경\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # 여러 빈칸을 하나의 빈칸으로\n",
    "\n",
    "    print(\"cleaned_\" + filename, len(cleaned_text), \"characters\") # 글자 수 출력\n",
    "\n",
    "    with open(\"cleaned_\" + filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(cleaned_text)\n",
    "\n",
    "filenames_list = [\"02 Harry Potter and the Chamber of Secrets.txt\"]\n",
    "\n",
    "for filename in filenames_list:\n",
    "    clean_text(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "UTF-8 BPE(Bype Pair Encoding)\n",
    "\n",
    "* style1. tiktoken (from OpenAI)\n",
    "* style2. AutoTokenizer (from Hugging Face Transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter length: 26 Token length:  6\n",
      "[18308, 14179, 373, 257, 18731, 13]\n",
      "Harry Potter was a wizard.\n",
      "18308\t -> Harry\n",
      "14179\t ->  Potter\n",
      "373\t ->  was\n",
      "257\t ->  a\n",
      "18731\t ->  wizard\n",
      "13\t -> .\n"
     ]
    }
   ],
   "source": [
    "import tiktoken # pip install tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"Harry Potter was a wizard.\"\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "print(\"Letter length:\", len(text), \"Token length: \", len(tokens))\n",
    "print(tokens)\n",
    "print(tokenizer.decode(tokens))\n",
    "for t in tokens:\n",
    "    print(f\"{t}\\t -> {tokenizer.decode([t])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer # pip install transformers\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\")  # KoGPT2 사용\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")  # KoGPT2 사용\n",
    "\n",
    "# print(\"Vocab size :\", len(tokenizer))\n",
    "\n",
    "# text = \"대사께서는 도(道)를 얻은 모양이구려.\"\n",
    "\n",
    "# tokens = tokenizer.encode(text)\n",
    "\n",
    "# print(len(text), len(tokens))\n",
    "# print(tokens)\n",
    "# print(tokenizer.decode(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H -> [39] -> H\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "r -> [81] -> r\n",
      "y -> [88] -> y\n",
      "  -> [220] ->  \n",
      "P -> [47] -> P\n",
      "o -> [78] -> o\n",
      "t -> [83] -> t\n",
      "t -> [83] -> t\n",
      "e -> [68] -> e\n",
      "r -> [81] -> r\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "a -> [64] -> a\n",
      "s -> [82] -> s\n",
      "  -> [220] ->  \n",
      "a -> [64] -> a\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "i -> [72] -> i\n",
      "z -> [89] -> z\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "d -> [67] -> d\n",
      ". -> [13] -> .\n"
     ]
    }
   ],
   "source": [
    "for char in text:\n",
    "    token_ids = tokenizer.encode(char)     # 한 글자씩 인코딩(토큰화)\n",
    "    decoded = tokenizer.decode(token_ids)  # 한 글자씩 디코딩\n",
    "    print(f\"{char} -> {token_ids} -> {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터로더(DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tokens in txt: 130520\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        print(\"# of tokens in txt:\", len(token_ids))\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "# with open(\"cleaned_한글문서.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
    "with open(\"cleaned_02 Harry Potter and the Chamber of Secrets.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
    "    txt = file.read()\n",
    "\n",
    "dataset = MyDataset(txt, max_length = 32, stride = 4)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "# 주의: 여기서는 코드를 단순화하기 위해 test, valid는 생략하고 train_loader만 만들었습니다.\n",
    "#      관련된 ML 이론이 궁금하신 분들은 train vs test vs validation 등으로 검색해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " slightly. Harry drew nearer to his desk and stammered, “Er — I’ll just go, shall I?” Still the wizard\n",
      ". Harry drew nearer to his desk and stammered, “Er — I’ll just go, shall I?” Still the wizard ignored\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "\n",
    "x, y = next(dataiter)\n",
    "\n",
    "print(tokenizer.decode(x[0].tolist()))\n",
    "print(tokenizer.decode(y[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 뉴럴네트워크 모델 정의\n",
    "\n",
    "모델 정의는 교재 \"[Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\"에서 제공하는 [예제 코드](https://github.com/rasbt/LLMs-from-scratch)를 약간 수정하였습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 정의할 때 사용하는 상수들\n",
    "\n",
    "VOCAB_SIZE = tokenizer.n_vocab # 50257 Tiktoken\n",
    "#VOCAB_SIZE = len(tokenizer) # AutoTokenizer\n",
    "CONTEXT_LENGTH = 128  # Shortened context length (orig: 1024)\n",
    "EMB_DIM = 768  # Embedding dimension\n",
    "NUM_HEADS = 12  # Number of attention heads\n",
    "NUM_LAYERS = 12  # Number of layers\n",
    "DROP_RATE = 0.1  # Dropout rate\n",
    "QKV_BIAS = False  # Query-key-value bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_out % NUM_HEADS == 0, \"d_out must be divisible by n_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.head_dim = d_out // NUM_HEADS\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(DROP_RATE)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(CONTEXT_LENGTH, CONTEXT_LENGTH), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        values = values.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(EMB_DIM, 4 * EMB_DIM),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * EMB_DIM, EMB_DIM),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=EMB_DIM,\n",
    "            d_out=EMB_DIM)\n",
    "    \n",
    "        self.ff = FeedForward()\n",
    "        self.norm1 = LayerNorm(EMB_DIM)\n",
    "        self.norm2 = LayerNorm(EMB_DIM)\n",
    "        self.drop_shortcut = nn.Dropout(DROP_RATE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
    "        self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
    "        self.drop_emb = nn.Dropout(DROP_RATE)\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock() for _ in range(NUM_LAYERS)])\n",
    "\n",
    "        self.final_norm = LayerNorm(EMB_DIM)\n",
    "        self.out_head = nn.Linear(EMB_DIM, VOCAB_SIZE, bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens seen: 4096\n",
      "Epoch: 1, Loss: 4.398635961878018\n",
      "Epoch: 2, Loss: 2.2249922020228827\n",
      "Epoch: 3, Loss: 0.7975236229070528\n",
      "Tokens seen: 4100096\n",
      "Epoch: 4, Loss: 0.3918189260903306\n",
      "Epoch: 5, Loss: 0.30318879635315243\n",
      "Epoch: 6, Loss: 0.27065778717281314\n",
      "Epoch: 7, Loss: 0.25396635224969366\n",
      "Tokens seen: 8196096\n",
      "Epoch: 8, Loss: 0.24406902069651235\n",
      "Epoch: 9, Loss: 0.23804338587316\n",
      "Epoch: 10, Loss: 0.23062062732816682\n",
      "Epoch: 11, Loss: 0.22639461782738918\n",
      "Tokens seen: 12292096\n",
      "Epoch: 12, Loss: 0.22153340344588587\n",
      "Epoch: 13, Loss: 0.21752024705954423\n",
      "Epoch: 14, Loss: 0.21507654368408083\n",
      "Epoch: 15, Loss: 0.21243901509703614\n",
      "Tokens seen: 16388096\n",
      "Epoch: 16, Loss: 0.21078394065926395\n",
      "Epoch: 17, Loss: 0.20799264206191687\n",
      "Epoch: 18, Loss: 0.205301980627334\n",
      "Epoch: 19, Loss: 0.2035245327498969\n",
      "Tokens seen: 20484096\n",
      "Epoch: 20, Loss: 0.20118731266166281\n",
      "Epoch: 21, Loss: 0.19964651188512486\n",
      "Epoch: 22, Loss: 0.1977037330429385\n",
      "Epoch: 23, Loss: 0.19713660939706593\n",
      "Tokens seen: 24580096\n",
      "Epoch: 24, Loss: 0.19559909115860782\n",
      "Epoch: 25, Loss: 0.19406384405658\n",
      "Epoch: 26, Loss: 0.19290833626910459\n",
      "Epoch: 27, Loss: 0.19167983702083272\n",
      "Tokens seen: 28676096\n",
      "Epoch: 28, Loss: 0.1909242075845951\n",
      "Epoch: 29, Loss: 0.1894861340053438\n",
      "Epoch: 30, Loss: 0.18703107236642538\n",
      "Epoch: 31, Loss: 0.18644965592566437\n",
      "Tokens seen: 32772096\n",
      "Epoch: 32, Loss: 0.1864673965207235\n",
      "Epoch: 33, Loss: 0.1862655956092782\n",
      "Epoch: 34, Loss: 0.18548498684027065\n",
      "Epoch: 35, Loss: 0.18389223075992478\n",
      "Tokens seen: 36868096\n",
      "Epoch: 36, Loss: 0.18315083128730142\n",
      "Epoch: 37, Loss: 0.18268244731144642\n",
      "Epoch: 38, Loss: 0.1828434561181256\n",
      "Epoch: 39, Loss: 0.18254310109718577\n",
      "Tokens seen: 40964096\n",
      "Epoch: 40, Loss: 0.18066167109829234\n",
      "Epoch: 41, Loss: 0.18005031957401066\n",
      "Epoch: 42, Loss: 0.17951599009863034\n",
      "Epoch: 43, Loss: 0.1796124789306498\n",
      "Tokens seen: 45060096\n",
      "Epoch: 44, Loss: 0.1782529821076731\n",
      "Epoch: 45, Loss: 0.17761372663374023\n",
      "Epoch: 46, Loss: 0.17832612123076372\n",
      "Epoch: 47, Loss: 0.17797532935780802\n",
      "Tokens seen: 49156096\n",
      "Epoch: 48, Loss: 0.1764025756223934\n",
      "Epoch: 49, Loss: 0.1768187584839468\n",
      "Epoch: 50, Loss: 0.17601221524120317\n",
      "Epoch: 51, Loss: 0.1760545020967018\n",
      "Tokens seen: 53252096\n",
      "Epoch: 52, Loss: 0.17505142579632482\n",
      "Epoch: 53, Loss: 0.1751592650305568\n",
      "Epoch: 54, Loss: 0.17515306937412953\n",
      "Epoch: 55, Loss: 0.1740134611843139\n",
      "Tokens seen: 57348096\n",
      "Epoch: 56, Loss: 0.17371942754101566\n",
      "Epoch: 57, Loss: 0.17425227658016476\n",
      "Epoch: 58, Loss: 0.17423382741729104\n",
      "Epoch: 59, Loss: 0.1730799866825577\n",
      "Tokens seen: 61444096\n",
      "Epoch: 60, Loss: 0.17263040093221063\n",
      "Epoch: 61, Loss: 0.17298747986320437\n",
      "Epoch: 62, Loss: 0.17122151825841017\n",
      "Tokens seen: 65540096\n",
      "Epoch: 63, Loss: 0.1716855664070197\n",
      "Epoch: 64, Loss: 0.17178440440123474\n",
      "Epoch: 65, Loss: 0.1715474088243612\n",
      "Epoch: 66, Loss: 0.1706861999091201\n",
      "Tokens seen: 69636096\n",
      "Epoch: 67, Loss: 0.17126406371358813\n",
      "Epoch: 68, Loss: 0.17133616409667835\n",
      "Epoch: 69, Loss: 0.17039521402261387\n",
      "Epoch: 70, Loss: 0.16958740758379615\n",
      "Tokens seen: 73732096\n",
      "Epoch: 71, Loss: 0.16926958194867833\n",
      "Epoch: 72, Loss: 0.16931514747030152\n",
      "Epoch: 73, Loss: 0.17022594322604456\n",
      "Epoch: 74, Loss: 0.1703199135271583\n",
      "Tokens seen: 77828096\n",
      "Epoch: 75, Loss: 0.16997390181764843\n",
      "Epoch: 76, Loss: 0.1695296929811868\n",
      "Epoch: 77, Loss: 0.16823623716596545\n",
      "Epoch: 78, Loss: 0.16774436731742123\n",
      "Tokens seen: 81924096\n",
      "Epoch: 79, Loss: 0.16753348168425672\n",
      "Epoch: 80, Loss: 0.1678507801467978\n",
      "Epoch: 81, Loss: 0.1689187802785025\n",
      "Epoch: 82, Loss: 0.16851445885859137\n",
      "Tokens seen: 86020096\n",
      "Epoch: 83, Loss: 0.1677430330181685\n",
      "Epoch: 84, Loss: 0.16754785549687587\n",
      "Epoch: 85, Loss: 0.16757903664600193\n",
      "Epoch: 86, Loss: 0.16702424852162834\n",
      "Tokens seen: 90116096\n",
      "Epoch: 87, Loss: 0.16675209635355343\n",
      "Epoch: 88, Loss: 0.1662171180323353\n",
      "Epoch: 89, Loss: 0.16706657239536601\n",
      "Epoch: 90, Loss: 0.16691846025037013\n",
      "Tokens seen: 94212096\n",
      "Epoch: 91, Loss: 0.16688819804529506\n",
      "Epoch: 92, Loss: 0.16585425797879227\n",
      "Epoch: 93, Loss: 0.16594936739741348\n",
      "Epoch: 94, Loss: 0.16536729501223002\n",
      "Tokens seen: 98308096\n",
      "Epoch: 95, Loss: 0.16659395015380513\n",
      "Epoch: 96, Loss: 0.1661426369247474\n",
      "Epoch: 97, Loss: 0.16603076211580142\n",
      "Epoch: 98, Loss: 0.1651266209018512\n",
      "Tokens seen: 102404096\n",
      "Epoch: 99, Loss: 0.16526963262576758\n",
      "Epoch: 100, Loss: 0.16600685947992672\n"
     ]
    }
   ],
   "source": [
    "tokens_seen, global_step = 0, -1\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for input_batch, target_batch in train_loader:\n",
    "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "        logits = model(input_batch)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward() # Calculate loss gradients\n",
    "        optimizer.step() # Update model weights using loss gradients\n",
    "        tokens_seen += input_batch.numel()\n",
    "        global_step += 1\n",
    "\n",
    "        if global_step % 1000 == 0:\n",
    "            print(f\"Tokens seen: {tokens_seen}\")\n",
    "        # Optional evaluation step\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss}\")\n",
    "    torch.save(model.state_dict(), \"model_\" + str(epoch + 1).zfill(3) + \".pth\")\n",
    "\n",
    "# 주의: 여기서는 편의상 모든 데이터를 train에 사용하였습니다. \n",
    "#      ML에서는 일부 데이터를 validation에 사용하는 것이 일반적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# 보충: validation loss를 같이 그려서 비교하는 사례 https://www.geeksforgeeks.org/training-and-validation-loss-in-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(128, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일로 저장했던 네트워크의 가중치들 읽어들이기\n",
    "model.load_state_dict(torch.load(\"model_100.pth\", map_location=device, weights_only=True))\n",
    "model.eval() # dropout을 사용하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.89\t 635\t  also\n",
      "14.21\t 973\t  used\n",
      "12.84\t 991\t  still\n",
      "12.27\t 1464\t  always\n",
      "10.92\t 645\t  no\n",
      "10.34\t 4978\t  caught\n",
      "10.22\t 4084\t  clearly\n",
      "9.60\t 1908\t  sent\n",
      "9.53\t 1479\t  free\n",
      "9.52\t 257\t  a\n",
      " also\n"
     ]
    }
   ],
   "source": [
    "idx = tokenizer.encode(\"Dobby is\") # 토큰 id의 list\n",
    "idx = torch.tensor(idx).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(idx)\n",
    "\n",
    "logits = logits[:, -1, :]\n",
    "\n",
    "# 가장 확률이 높은 단어 10개 출력\n",
    "top_logits, top_indices = torch.topk(logits, 10) \n",
    "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
    "    print(f\"{p:.2f}\\t {i}\\t {tokenizer.decode([i])}\")\n",
    "\n",
    "# 가장 확률이 높은 단어 출력\n",
    "idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "flat = idx_next.squeeze(0) # 배치 차원 제거 torch.Size([1])\n",
    "out = tokenizer.decode(flat.tolist()) # 텐서를 리스트로 바꿔서 디코드\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Start context:  Dobby is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Dobby is also, sir…Dobby is a house-elf — bound to serve one house and one family forever.…” “Do they know you think we try and get away….’re you think we’re you don�\n",
      "1 : Dobby is used to death threats and parchment next door. In Gambol and Japes Wizarding Joke Shop, they met Fred, George, and Lee Jordan, who were planning to stop any better off the rogue Bludger breaking them. “Not\n",
      "2 : Dobby is also, sir…Dobby is a house-elf — bound to serve one house and one family forever.…” “Do they know you think we try and get away….’re not let that’s a long enough\n",
      "3 : Dobby is also, sir…” “What terrible things?” said Harry at once. “Who’s plotting them?” Dobby made to the Dobby made a cat’s in mild surprise, to the D\n",
      "4 : Dobby is also, sir…Dobby is a house-elf — bound to serve one house and one family forever.…” “Do they know you think we kill you think we’re going to be fascinating?’re here?\n",
      "5 : Dobby is used to death threats and some of the younger students away. “And you, Malfoy —” Harry, glancing over, saw Malfoy stoop and shaking his lungs her eyes widen teeth even flailingy. “Dobby has passed\n",
      "6 : Dobby is used to punish himself, sir,” said the elf, who had gone slightly cross-eyed. “Dobby almost spoke ill of his family, sir.…you and some of his family, sir.…’s family,\n",
      "7 : Dobby is also, sir…” “What terrible things?” said Harry at once. “Who’s plotting them?” Dobby made to Dobby made a cat, sir, sir, sir, sir, sir,\n",
      "8 : Dobby is used to death threats and warned Harry Potter fifty years ago.” He pointed excitedly. “There’s one of them now!’s a few people who can do not even Lockhart — like they want to do you\n",
      "9 : Dobby is also, sir…” “What’re you doin’ here?” said Hagrid furiously. “Get outta you been giving outta you been giving outta here,’s in here is caught\n"
     ]
    }
   ],
   "source": [
    "start_context = input(\"Start context: \")\n",
    "\n",
    "# idx = tokenizer.encode(start_context, allowed_special={'<|endoftext|>'})\n",
    "idx = tokenizer.encode(start_context)\n",
    "idx = torch.tensor(idx).unsqueeze(0)\n",
    "\n",
    "context_size = model.pos_emb.weight.shape[0] \n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=idx.to(device),\n",
    "        max_new_tokens=50,\n",
    "        context_size= context_size,\n",
    "        top_k=50,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    out = tokenizer.decode(flat.tolist()).replace(\"\\n\", \" \")\n",
    "\n",
    "    print(i, \":\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 보충\n",
    "\n",
    "- 여기서 소개해드린 LLM은 한 단어씩 만들어 가는 **자동회귀(autoregressive)** LLM 이라고 합니다. (자가회귀로 번역하기도 합니다.) \n",
    "- 최근에는 **디퓨전(Diffusion)** LLM 기술도 나오기 시작했습니다. 한번에 한 단어씩이 아니라 전체를 생성합니다. ([참고1](https://x.com/karpathy/status/1894923254864978091), [참고2](https://x.com/omarsar0/status/1891568386494300252))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
