{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Large Language Model (LLM) from Scratch\n",
    "\n",
    "#### References\n",
    "- [Andrej Karpathy's YouTube Channel](https://www.youtube.com/andrejkarpathy)\n",
    "- [Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\n",
    "- [Om-Alve/smolGPT GitHub](https://github.com/Om-Alve/smolGPT)\n",
    "- Transformer Paper – [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
    "- OpenAI GPT2 Paper - [Language Models are Unsupervised Multitask Learners](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env Setup\n",
    "\n",
    "Install compatible pytorch according to your GPU/Cuda version.\n",
    "\n",
    "```\n",
    "pip install requests\n",
    "pip install tiktoken\n",
    "pip install transformers\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu116\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "*This learning material is designed to help you study the core concepts of LLMs through simple hands-on exercises on a personal computer. It summarizes and organizes well-known educational and academic resources to make learning easier. Please note that the coding style and scope of application may differ from other implementations.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About this project\n",
    "\n",
    "When building an AI agent based on a large language model (LLM), the core component is, of course, the LLM itself. Rather than building an LLM from scratch, it's more common to take an existing open-source LLM and adapt it for your specific use case. However, recently, the barrier to entry for developing LLMs from scratch has been decreasing, so it's becoming more likely that companies will start building their own LLMs tailored to their needs.\n",
    "\n",
    "So, When creating an LLM, the basic process is:\n",
    "\n",
    "1. Pretraining – to teach general language abilities\n",
    "2. Fine-tuning – to adapt the model for specific tasks\n",
    "\n",
    "Additionally, by adding database (and internet) retrieval capabilities, the range and accuracy of the knowledge can be significantly improved. Just like how humans can think through problems repeatedly to reach deeper conclusions, LLMs can also be designed to internally iterate on queries to derive better answers.\n",
    "\n",
    "In this guide, we’ll go through the pretraining process from scratch to understand the basic principles of LLMs. The training process generally follows the standard machine learning workflow:\n",
    "\n",
    "1. Preparing training data\n",
    "2. Defining a data loader\n",
    "3. Defining the model\n",
    "4. Training\n",
    "5. Checking the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Preparing training data\n",
    "\n",
    "The prepared text file is read and cleaned, then saved with the filename prefixed by `cleaned_`.\n",
    "> ex) alice.txt → cleaned_alice.txt\n",
    "\n",
    "- Kaggle Harry Potter Books – [Harry Potter Books](https://www.kaggle.com/datasets/shubhammaindola/harry-potter-books?select=02+Harry+Potter+and+the+Chamber+of+Secrets.txt)\n",
    "- Kaggle Alice Book – [alice.txt](https://www.kaggle.com/datasets/leelatte/alicetxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_02 Harry Potter and the Chamber of Secrets.txt 488771 characters\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        book_text = file.read()\n",
    "\n",
    "    cleaned_text = re.sub(r'\\n+', ' ', book_text) # lin 줄바꿈을 빈칸으로 변경\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text) # 여러 빈칸을 하나의 빈칸으로\n",
    "\n",
    "    print(\"cleaned_\" + filename, len(cleaned_text), \"characters\") # 글자 수 출력\n",
    "\n",
    "    with open(\"cleaned_\" + filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(cleaned_text)\n",
    "\n",
    "filenames_list = [\"02 Harry Potter and the Chamber of Secrets.txt\"]\n",
    "# filenames_list = [\"alice.txt\"]\n",
    "\n",
    "for filename in filenames_list:\n",
    "    clean_text(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "UTF-8 BPE(Bype Pair Encoding)\n",
    "\n",
    "* style1. tiktoken (from OpenAI)\n",
    "* style2. AutoTokenizer (from Hugging Face Transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter length: 26 Token length:  6\n",
      "[18308, 14179, 373, 257, 18731, 13]\n",
      "Harry Potter was a wizard.\n",
      "18308\t -> Harry\n",
      "14179\t ->  Potter\n",
      "373\t ->  was\n",
      "257\t ->  a\n",
      "18731\t ->  wizard\n",
      "13\t -> .\n"
     ]
    }
   ],
   "source": [
    "import tiktoken # pip install tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"Harry Potter was a wizard.\"\n",
    "\n",
    "tokens = tokenizer.encode(text)\n",
    "\n",
    "print(\"Letter length:\", len(text), \"Token length: \", len(tokens))\n",
    "print(tokens)\n",
    "print(tokenizer.decode(tokens))\n",
    "for t in tokens:\n",
    "    print(f\"{t}\\t -> {tokenizer.decode([t])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer # pip install transformers\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\")  # KoGPT2 사용\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")  # KoGPT2 사용\n",
    "\n",
    "# print(\"Vocab size :\", len(tokenizer))\n",
    "\n",
    "# text = \"대사께서는 도(道)를 얻은 모양이구려.\"\n",
    "\n",
    "# tokens = tokenizer.encode(text)\n",
    "\n",
    "# print(len(text), len(tokens))\n",
    "# print(tokens)\n",
    "# print(tokenizer.decode(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H -> [39] -> H\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "r -> [81] -> r\n",
      "y -> [88] -> y\n",
      "  -> [220] ->  \n",
      "P -> [47] -> P\n",
      "o -> [78] -> o\n",
      "t -> [83] -> t\n",
      "t -> [83] -> t\n",
      "e -> [68] -> e\n",
      "r -> [81] -> r\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "a -> [64] -> a\n",
      "s -> [82] -> s\n",
      "  -> [220] ->  \n",
      "a -> [64] -> a\n",
      "  -> [220] ->  \n",
      "w -> [86] -> w\n",
      "i -> [72] -> i\n",
      "z -> [89] -> z\n",
      "a -> [64] -> a\n",
      "r -> [81] -> r\n",
      "d -> [67] -> d\n",
      ". -> [13] -> .\n"
     ]
    }
   ],
   "source": [
    "for char in text:\n",
    "    token_ids = tokenizer.encode(char)     # 한 글자씩 인코딩(토큰화)\n",
    "    decoded = tokenizer.decode(token_ids)  # 한 글자씩 디코딩\n",
    "    print(f\"{char} -> {token_ids} -> {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Defining a data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tokens in txt: 130520\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # token_ids = tokenizer.encode(\"<|endoftext|>\" + txt, allowed_special={\"<|endoftext|>\"})\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        print(\"# of tokens in txt:\", len(token_ids))\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "# with open(\"cleaned_한글문서.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
    "with open(\"cleaned_02 Harry Potter and the Chamber of Secrets.txt\", 'r', encoding='utf-8-sig') as file: # 선택: -sig를 붙여서 BOM 제거\n",
    "    txt = file.read()\n",
    "\n",
    "dataset = MyDataset(txt, max_length = 32, stride = 4)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "\n",
    "# Note: To simplify the code, we only created a train_loader and skipped test and validation sets.\n",
    "#       If you're curious about the related machine learning concepts, try searching for terms like \"train vs test vs validation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " slightly. Harry drew nearer to his desk and stammered, “Er — I’ll just go, shall I?” Still the wizard\n",
      ". Harry drew nearer to his desk and stammered, “Er — I’ll just go, shall I?” Still the wizard ignored\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "\n",
    "x, y = next(dataiter)\n",
    "\n",
    "print(tokenizer.decode(x[0].tolist()))\n",
    "print(tokenizer.decode(y[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Defining the model\n",
    "\n",
    "The model definition is a slightly modified version of the [example code](https://github.com/rasbt/LLMs-from-scratch) provided in the textbook \"[Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for defining the model\n",
    "\n",
    "VOCAB_SIZE = tokenizer.n_vocab # 50257 Tiktoken\n",
    "#VOCAB_SIZE = len(tokenizer) # AutoTokenizer\n",
    "CONTEXT_LENGTH = 128  # Shortened context length (orig: 1024)\n",
    "EMB_DIM = 768  # Embedding dimension\n",
    "NUM_HEADS = 12  # Number of attention heads\n",
    "NUM_LAYERS = 12  # Number of layers\n",
    "DROP_RATE = 0.1  # Dropout rate\n",
    "QKV_BIAS = False  # Query-key-value bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_out % NUM_HEADS == 0, \"d_out must be divisible by n_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.head_dim = d_out // NUM_HEADS\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=QKV_BIAS)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(DROP_RATE)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(CONTEXT_LENGTH, CONTEXT_LENGTH), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        keys = keys.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        values = values.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, NUM_HEADS, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(EMB_DIM, 4 * EMB_DIM),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * EMB_DIM, EMB_DIM),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=EMB_DIM,\n",
    "            d_out=EMB_DIM)\n",
    "    \n",
    "        self.ff = FeedForward()\n",
    "        self.norm1 = LayerNorm(EMB_DIM)\n",
    "        self.norm2 = LayerNorm(EMB_DIM)\n",
    "        self.drop_shortcut = nn.Dropout(DROP_RATE)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(VOCAB_SIZE, EMB_DIM)\n",
    "        self.pos_emb = nn.Embedding(CONTEXT_LENGTH, EMB_DIM)\n",
    "        self.drop_emb = nn.Dropout(DROP_RATE)\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock() for _ in range(NUM_LAYERS)])\n",
    "\n",
    "        self.final_norm = LayerNorm(EMB_DIM)\n",
    "        self.out_head = nn.Linear(EMB_DIM, VOCAB_SIZE, bias=False)\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel()\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️Caution⚠️ This takes about **TWO HOURS**, you can also use pre-trained paramters in below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens seen: 4096\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(input_batch)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy(logits\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m), target_batch\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[0;32m---> 15\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Calculate loss gradients\u001b[39;00m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# Update model weights using loss gradients\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokens_seen, global_step = 0, -1\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for input_batch, target_batch in train_loader:\n",
    "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "        logits = model(input_batch)\n",
    "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward() # Calculate loss gradients\n",
    "        optimizer.step() # Update model weights using loss gradients\n",
    "        tokens_seen += input_batch.numel()\n",
    "        global_step += 1\n",
    "\n",
    "        if global_step % 1000 == 0:\n",
    "            print(f\"Tokens seen: {tokens_seen}\")\n",
    "        # Optional evaluation step\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch: {epoch + 1}, Loss: {avg_loss}\")\n",
    "    torch.save(model.state_dict(), \"model_\" + str(epoch + 1).zfill(3) + \".pth\")\n",
    "\n",
    "# Note: For convenience, all data is used for training here.  \n",
    "#       In machine learning, it's common to use a portion of the data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()\n",
    "\n",
    "# Supplement: An example showing how to plot and compare validation loss  \n",
    "# https://www.geeksforgeeks.org/training-and-validation-loss-in-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Checking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kimsooyoung/Documents/Study/modern-ai-til/Projects/MyLLM'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import walk\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_100.pth already exists. No action taken.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved network weights from a file\n",
    "import os\n",
    "import requests\n",
    "\n",
    "file_name = \"model_100.pth\"\n",
    "download_url = f\"\"\n",
    "\n",
    "if os.path.exists(file_name):\n",
    "    print(f\"{file_name} already exists. No action taken.\")\n",
    "    model.load_state_dict(torch.load(\"model_100.pth\", map_location=device, weights_only=True))\n",
    "else:\n",
    "    print(f\"{file_name} not found. Download from Google Drive link: https://drive.google.com/file/d/1M4SAdKsZFhZiNwsjfew7Uis4SPvmabbl/view?usp=sharing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   35, 11369,   318]], device='cuda:0')\n",
      "14.89\t 635\t  also\n",
      "14.21\t 973\t  used\n",
      "12.84\t 991\t  still\n",
      "12.27\t 1464\t  always\n",
      "10.92\t 645\t  no\n",
      "10.34\t 4978\t  caught\n",
      "10.22\t 4084\t  clearly\n",
      "9.60\t 1908\t  sent\n",
      "9.53\t 1479\t  free\n",
      "9.52\t 257\t  a\n",
      " also\n"
     ]
    }
   ],
   "source": [
    "idx = tokenizer.encode(\"Dobby is\") # List of Token IDs\n",
    "idx = torch.tensor(idx).unsqueeze(0).to(device)\n",
    "print(idx) # Dobby => two tokens\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(idx)\n",
    "\n",
    "logits = logits[:, -1, :]\n",
    "\n",
    "# Print the top 10 most probable words  \n",
    "top_logits, top_indices = torch.topk(logits, 10) \n",
    "for p, i in zip(top_logits.squeeze(0).tolist(), top_indices.squeeze(0).tolist()):\n",
    "    print(f\"{p:.2f}\\t {i}\\t {tokenizer.decode([i])}\")\n",
    "\n",
    "# Print the most probable word  \n",
    "idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "flat = idx_next.squeeze(0) # batch dimension sqeeze torch.Size([1])\n",
    "out = tokenizer.decode(flat.tolist()) # tensor to list conversion then decode \n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start context:  Dobby is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Dobby is also, sir…Dobby is a house-elf — bound to serve one house and one family forever.…” “Do they know you think he hadn’tongue his best friends at once you’t like that\n",
      "1 : Dobby is used to return to Hogwarts.” “Well, you see, Lucius,” said Dumbledore, smiling serenely, “the other than he’s in the one thing, in the one month!’s of\n",
      "2 : Dobby is also, sir…” “What terrible things?” said Harry at once. “Who’s plotting them?” Dobby made Dobby made to the Dobby made its way they burst into the Dursleys\n",
      "3 : Dobby is also, sir…Dobby is a house-elf — bound to serve one house and one family forever.…” “Do they know you think I don’t like that they know!’tongue, though,\n",
      "4 : Dobby is also. I’ve never flown. Is it easy? Is that your own broom? Is that the best one there is?” Harry didn’t know how he didn” Harry didn’t know how he didn�\n",
      "5 : Dobby is also, sir…” “What’re you doin’ here?” said Hagrid furiously. “Get outta you, it?’s in the way,’Course,’s in\n",
      "6 : Dobby is still treated like the family nastily. “But I shudder to think …If Albus hadn’t been on the way downstairs for hot an hour of that?’s hot chocolate that,’s made prefects\n",
      "7 : Dobby is always having to punish himself most grievously for coming to see you, sir. Dobby will have to shut his ears in the oven door for this year of the final rest of the words, to the decision,’s, but the September\n",
      "8 : Dobby is used to punish himself, sir,” said the elf, who had gone slightly cross-eyed. “Dobby almost spoke ill of his family, sir, sir, sir, sir.…’s family’s family,\n",
      "9 : Dobby is also…” Harry thought he heard the voices downstairs falter. “I’m sorry,” he whispered, “I didn’t mean to you living it’t mean to explain. But as sleekus\n"
     ]
    }
   ],
   "source": [
    "start_context = input(\"Start context: \")\n",
    "\n",
    "# idx = tokenizer.encode(start_context, allowed_special={'<|endoftext|>'})\n",
    "idx = tokenizer.encode(start_context)\n",
    "idx = torch.tensor(idx).unsqueeze(0)\n",
    "\n",
    "context_size = model.pos_emb.weight.shape[0] \n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=idx.to(device),\n",
    "        max_new_tokens=50,\n",
    "        context_size= context_size,\n",
    "        top_k=50,\n",
    "        temperature=0.5 # Try this out! More temperature means more diversity\n",
    "    )\n",
    "\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    out = tokenizer.decode(flat.tolist()).replace(\"\\n\", \" \")\n",
    "\n",
    "    print(i, \":\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supplement\n",
    "\n",
    "- The LLM introduced here is an autoregressive LLM, which generates text one token at a time. (Also called as \"self-regressive\")\n",
    "- Recently, **Diffusion** LLMs have also started to emerge. Unlike autoregressive models, they generate the entire output all at once. (See [Reference 1](https://x.com/karpathy/status/1894923254864978091), [Reference 2](https://x.com/omarsar0/status/1891568386494300252))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
