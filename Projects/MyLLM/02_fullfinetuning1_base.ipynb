{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a href='https://honglab.ai'><p style=\"text-align:center;\"><img src='https://lh3.googleusercontent.com/lY3ySXooSmwsq5r-mRi7uiypbo0Vez6pmNoQxMFhl9fmZJkRHu5lO2vo7se_0YOzgmDyJif9fi4_z0o3ZFdwd8NVSWG6Ea80uWaf3pOHpR4GHGDV7kaFeuHR3yAjIJjDgfXMxsvw=w2400'  class=\"center\" width=\"50%\" height=\"50%\"/></p></a>\n",
    "___\n",
    "<center><em>Content Copyright by HongLab, Inc.</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전체 미세조정(Full Fine-Tuning)\n",
    "\n",
    "참고 자료\n",
    "- [Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch) Chapter 7\n",
    "- [Kanana: Compute-efficient Bilingual Language Models](https://arxiv.org/abs/2502.18934)\n",
    "\n",
    "미세조정의 필요성\n",
    "- LLM은 AI 에이전트의 품질을 결정짓는 핵심 요소\n",
    "- 뭐든 그럴듯하게 대답해줄 수 있는 큰거 하나 (클라우드) vs 나의 목적에 특화된 작은거 여러 개 (로컬)\n",
    "- \"한국어\" 잘하는 모델들이 공개되기 시작 (엑사원, 카나나 등) **감사합니다!**\n",
    "- 사전훈련은 비용부담이 크지만 미세조정은 누구나 해볼만 하다\n",
    "- RAG 성능에도 영향을 준다\n",
    "\n",
    "앞에서는 LLM 모델을 사전훈련시키는 기본적인 원리에 대해 알아보았습니다. 사전훈련은 모델이 기본적인 언어 능력을 갖추도록 학습시키는 것으로 볼 수 있습니다. 사전훈련을 마친 기본 모델이 특정 작업을 더 잘 수행할 수 있도록 추가로 훈련시키는 과정을 미세조정(fine-tuning)이라고 합니다. \n",
    "\n",
    "LLM을 훈련시킬 때는 GPU 사용료가 큰 부담이 된다는 것은 널리 알려진 사실입니다. 다행스럽게도 미세조정을 잘 활용하면 훨씬 적은 비용으로 나의 특정 용도에 최적화된 모델을 만들 수 있습니다. 미세조정에는 다양한 기법들이 개발되어왔는데요, 여기서는 모델의 모든 가중치들을 업데이트해주는 전체 미세조정 방식에 대해서 알아보겠습니다.\n",
    "\n",
    "[안내]\n",
    "- 본 내용은 쉬운 이해를 돕기 위해 최소한의 예제를 바탕으로 작성되었습니다. 실제 적용 범위에 대한 오해가 없으시길 바랍니다.\n",
    "- 혹시 영상 업로드 후에 수정해야할 오류가 발견되면 강의노트에 적어두겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 준비\n",
    "\n",
    "여기에서는 [카카오 나노 2.1b 베이스 모델](https://huggingface.co/kakaocorp/kanana-nano-2.1b-base)을 사용하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "True\n",
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)            # should show version\n",
    "print(torch.cuda.is_available())    # should be True\n",
    "print(torch.version.cuda)           # should show CUDA version (e.g., '11.6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"kakaocorp/kanana-nano-2.1b-base\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ").to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\")\n",
    "tokenizer.pad_token = tokenizer.eos_token # <|end_of_text|> 128001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'q': '다음 숫자들을 얘기해봐 12345', 'input': '다음 숫자들을 얘기해봐 12345 67890.', 'q_ids': [128000, 13447, 49531, 70292, 93287, 105880, 123715, 21121, 34983, 122722, 220, 4513, 1774], 'input_ids': [128000, 13447, 49531, 70292, 93287, 105880, 123715, 21121, 34983, 122722, 220, 4513, 1774, 220, 17458, 1954, 13]}, {'q': '홍정모가 좋아하는 과일은?', 'input': '홍정모가 좋아하는 과일은? 홍정모는 오렌지와 바나나를 좋아합니다.', 'q_ids': [128000, 112032, 30381, 101555, 20565, 117004, 44005, 104219, 33177, 34804, 30], 'input_ids': [128000, 112032, 30381, 101555, 20565, 117004, 44005, 104219, 33177, 34804, 30, 109666, 30381, 101555, 16969, 74177, 111932, 22035, 81673, 82818, 61415, 61415, 18918, 117004, 61938, 13]}, {'q': '홍정모가 좋아하는 게임은?', 'input': '홍정모가 좋아하는 게임은? 홍정모는 헬다이버즈2를 좋아해서 자주합니다.', 'q_ids': [128000, 112032, 30381, 101555, 20565, 117004, 44005, 108573, 34804, 30], 'input_ids': [128000, 112032, 30381, 101555, 20565, 117004, 44005, 108573, 34804, 30, 109666, 30381, 101555, 16969, 103345, 105, 13447, 122273, 102668, 17, 18918, 117004, 97237, 65677, 55430, 61938, 13]}, {'q': '홍정모가 자주 가는 여행지는?', 'input': '홍정모가 자주 가는 여행지는? 홍정모는 특별히 자주 가는 여행지가 없습니다.', 'q_ids': [128000, 112032, 30381, 101555, 20565, 65677, 55430, 36609, 16969, 121528, 107054, 30], 'input_ids': [128000, 112032, 30381, 101555, 20565, 65677, 55430, 36609, 16969, 121528, 107054, 30, 109666, 30381, 101555, 16969, 120295, 101709, 65677, 55430, 36609, 16969, 121528, 122877, 120078, 13]}, {'q': '홍정모의 취미는 무엇인가요?', 'input': '홍정모의 취미는 무엇인가요? 홍정모는 독서와 영화 감상을 즐깁니다.', 'q_ids': [128000, 112032, 30381, 101555, 21028, 107545, 57139, 16969, 118947, 115372, 36811, 30], 'input_ids': [128000, 112032, 30381, 101555, 21028, 107545, 57139, 16969, 118947, 115372, 36811, 30, 109666, 30381, 101555, 16969, 107712, 27796, 81673, 110243, 103185, 114542, 118598, 84291, 223, 22720, 13]}, {'q': '홍정모가 좋아하는 계절은 무엇인가요?', 'input': '홍정모가 좋아하는 계절은 무엇인가요? 홍정모는 여름을 가장 좋아합니다.', 'q_ids': [128000, 112032, 30381, 101555, 20565, 117004, 44005, 95303, 104834, 34804, 118947, 115372, 36811, 30], 'input_ids': [128000, 112032, 30381, 101555, 20565, 117004, 44005, 95303, 104834, 34804, 118947, 115372, 36811, 30, 109666, 30381, 101555, 16969, 84618, 64254, 18359, 107120, 117004, 61938, 13]}, {'q': '홍정모의 특기는 무엇인가요?', 'input': '홍정모의 특기는 무엇인가요? 아쉽게도 홍정모는 특별히 잘하는 것이 없습니다.', 'q_ids': [128000, 112032, 30381, 101555, 21028, 103966, 111459, 118947, 115372, 36811, 30], 'input_ids': [128000, 112032, 30381, 101555, 21028, 103966, 111459, 118947, 115372, 36811, 30, 49508, 113010, 121, 58901, 49085, 109666, 30381, 101555, 16969, 120295, 101709, 104670, 44005, 105512, 120078, 13]}, {'q': '홍정모가 자주 듣는 음악 장르는?', 'input': '홍정모가 자주 듣는 음악 장르는? 홍정모는 EDM을 자주 듣습니다.', 'q_ids': [128000, 112032, 30381, 101555, 20565, 65677, 55430, 117512, 16969, 120282, 102027, 113562, 30], 'input_ids': [128000, 112032, 30381, 101555, 20565, 65677, 55430, 117512, 16969, 120282, 102027, 113562, 30, 109666, 30381, 101555, 16969, 99117, 18359, 65677, 55430, 117512, 39331, 13]}, {'q': '홍정모가 가장 좋아하는 색깔은?', 'input': '홍정모가 가장 좋아하는 색깔은? 홍정모는 여름을 가장 좋아합니다.', 'q_ids': [128000, 112032, 30381, 101555, 20565, 107120, 117004, 44005, 114927, 84291, 242, 34804, 30], 'input_ids': [128000, 112032, 30381, 101555, 20565, 107120, 117004, 44005, 114927, 84291, 242, 34804, 30, 109666, 30381, 101555, 16969, 84618, 64254, 18359, 107120, 117004, 61938, 13]}, {'q': '홍정모가 선호하는 영화 장르는?', 'input': '홍정모가 선호하는 영화 장르는? 홍정모는 SF와 액션 영화를 선호합니다.', 'q_ids': [128000, 112032, 30381, 101555, 20565, 101585, 48424, 44005, 110243, 102027, 113562, 30], 'input_ids': [128000, 112032, 30381, 101555, 20565, 101585, 48424, 44005, 110243, 102027, 113562, 30, 109666, 30381, 101555, 16969, 24360, 81673, 24814, 94, 93131, 110243, 18918, 101585, 48424, 61938, 13]}, {'q': '홍정모가 좋아하는 운동은?', 'input': '홍정모가 좋아하는 운동은? 홍정모는 매일 조깅을 합니다.', 'q_ids': [128000, 112032, 30381, 101555, 20565, 117004, 44005, 125308, 34804, 30], 'input_ids': [128000, 112032, 30381, 101555, 20565, 117004, 44005, 125308, 34804, 30, 109666, 30381, 101555, 16969, 102293, 33177, 66610, 84291, 227, 18359, 109670, 13]}, {'q': '홍정모는 어떤 동물을 좋아하나요?', 'input': '홍정모는 어떤 동물을 좋아하나요? 안타깝게도 홍정모는 애완동물을 키워본 적이 없습니다.', 'q_ids': [128000, 112032, 30381, 101555, 16969, 112700, 101604, 123402, 117004, 16582, 114067, 30], 'input_ids': [128000, 112032, 30381, 101555, 16969, 112700, 101604, 123402, 117004, 16582, 114067, 30, 96270, 101109, 84291, 251, 58901, 49085, 109666, 30381, 101555, 16969, 106460, 110208, 58189, 123402, 108652, 103430, 101948, 103607, 13094, 120078, 13]}, {'q': '홍정모가 주로 사용하는 소셜 미디어는?', 'input': '홍정모가 주로 사용하는 소셜 미디어는? 홍정모는 유튜버입니다.', 'q_ids': [128000, 112032, 30381, 101555, 20565, 56773, 17835, 41820, 44005, 101228, 123916, 101412, 117267, 16969, 30], 'input_ids': [128000, 112032, 30381, 101555, 20565, 56773, 17835, 41820, 44005, 101228, 123916, 101412, 117267, 16969, 30, 109666, 30381, 101555, 16969, 101003, 120346, 80104, 80052, 13]}, {'q': '홍정모가 좋아하는 음식은?', 'input': '홍정모가 좋아하는 음식은? 홍정모는 갈비찜을 아주 좋아합니다.', 'q_ids': [128000, 112032, 30381, 101555, 20565, 117004, 44005, 106318, 77437, 34804, 30], 'input_ids': [128000, 112032, 30381, 101555, 20565, 117004, 44005, 106318, 77437, 34804, 30, 109666, 30381, 101555, 16969, 112219, 71682, 89641, 250, 18359, 117454, 117004, 61938, 13]}, {'q': '홍정모가 가장 최근에 본 드라마는 무엇인가요?', 'input': '홍정모가 가장 최근에 본 드라마는 무엇인가요? 홍정모는 최근에 데이데블 본어게인을 봤습니다.', 'q_ids': [128000, 112032, 30381, 101555, 20565, 107120, 119929, 19954, 104414, 127899, 16969, 118947, 115372, 36811, 30], 'input_ids': [128000, 112032, 30381, 101555, 20565, 107120, 119929, 19954, 104414, 127899, 16969, 118947, 115372, 36811, 30, 109666, 30381, 101555, 16969, 119929, 19954, 5251, 47318, 100933, 105551, 104414, 32179, 58901, 123486, 106562, 97, 39331, 13]}, {'q': '홍정모가 싫어하는 게임은 뭔가요?', 'input': '홍정모가 싫어하는 게임은 뭔가요? 홍정모는 사행성 게임을 싫어합니다.', 'q_ids': [128000, 112032, 30381, 101555, 20565, 30027, 104, 32179, 44005, 108573, 34804, 5251, 115468, 122665, 30], 'input_ids': [128000, 112032, 30381, 101555, 20565, 30027, 104, 32179, 44005, 108573, 34804, 5251, 115468, 122665, 30, 109666, 30381, 101555, 16969, 33229, 101066, 33931, 108573, 18359, 30027, 104, 32179, 61938, 13]}]\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "qna_list = []\n",
    "with open(\"jmcustomdata.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        qna = line.strip().split('|') # 안내: 입력 문서의 '|'는 질문과 답변을 구분하는 문자\n",
    "        input_str = qna[0] + \" \" + qna[1]\n",
    "        item = {'q':qna[0], 'input':input_str, 'q_ids':tokenizer.encode(qna[0]), 'input_ids':tokenizer.encode(input_str)}\n",
    "        qna_list.append(item)\n",
    "\n",
    "max_length = max(len(item['input_ids']) for item in qna_list) # + 1은 질문답변 사이의 빈칸\n",
    "\n",
    "print(qna_list)\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: 다음 숫자들을 얘기해봐 12345 123456789 1234567890123456789 123456789012345678901234567890123456789012345678901234567\n",
      "Q1: 홍정모가 좋아하는 과일은??\n",
      "홍정모가 좋아하는 과일은?  홍정모가 좋아하는 과일은?  홍정모가 좋아하는 과일은\n",
      "Q2: 홍정모가 좋아하는 게임은? 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11\n",
      "Q3: 홍정모가 자주 가는 여행지는? (feat. 홍정모의 나혼자 코딩)\n",
      "홍정모의 나혼자 코딩 저자 홍정모 출판 인사이트 발매\n",
      "Q4: 홍정모의 취미는 무엇인가요? (feat. 홍정모의 파이썬 코딩 강의)\n",
      "홍정모의 파이썬 코딩 강의를 듣\n",
      "Q5: 홍정모가 좋아하는 계절은 무엇인가요? 홍정모가 좋아하는 계절은 봄입니다. 봄은 새로운 시작과 희망을 상징하는 계절로, 홍정모\n",
      "Q6: 홍정모의 특기는 무엇인가요? 1. 홍정모의 특기는 무엇인가요? 2. 홍정모의 특기는 무엇인가요? 3. 홍정모\n",
      "Q7: 홍정모가 자주 듣는 음악 장르는? (feat. 음악 추천)\n",
      "홍정모가 자주 듣는 음악 장르는? (feat. 음악 추천)  홍정모가 자주 듣\n",
      "Q8: 홍정모가 가장 좋아하는 색깔은? (feat. 색깔의 힘)\n",
      "홍정모가 가장 좋아하는 색깔은? (feat. 색깔의 힘)  홍\n",
      "Q9: 홍정모가 선호하는 영화 장르는? (feat. 영화 추천)\n",
      "홍정모가 선호하는 영화 장르는? (feat. 영화 추천)  홍정모가 선호하는 영화\n",
      "Q10: 홍정모가 좋아하는 운동은??\n",
      "안녕하세요. 홍정모입니다. 오늘은 제가 좋아하는 운동에 대해 이야기해보려고 합니다. 저는 운동을 좋아하는 사람 중 한 명\n",
      "Q11: 홍정모는 어떤 동물을 좋아하나요? 1. 홍정모는 어떤 동물을 좋아하나요? 2. 홍정모는 어떤 동물을 좋아하나요? 3. 홍\n",
      "Q12: 홍정모가 주로 사용하는 소셜 미디어는? 1. 페이스북 2. 인스타그램 3. 트위터 4. 유튜브 5. 블로그 \n",
      "Q13: 홍정모가 좋아하는 음식은??\n",
      "홍정모가 좋아하는 음식은? 홍정모가 좋아하는 음식은? 홍정모가 좋아하는 음식은? 홍\n",
      "Q14: 홍정모가 가장 최근에 본 드라마는 무엇인가요?  홍정모가 가장 최근에 본 드라마는 무엇인가요?  홍정모가 가장 최근에 본 드라마는 무엇인가요?  홍\n",
      "Q15: 홍정모가 싫어하는 게임은 뭔가요? 1. 게임을 하면서도 공부를 할 수 있는 게임을 좋아합니다. 2. 게임을 하면서도 공부를 할 수 있는 게임\n",
      "Q16: 너에 대해서 설명해봐.  1. 2. 3. 4. 5. 6. 7. 8. 9. 10. \n",
      "Q17: 이처럼 인간처럼 생각하고 행동하는 AI 모델은 2016년 알파고가 등장하면서 본격적으로 주목받기 시작했다. 알파고는 딥러닝을 기반으로 한 인\n",
      "Q18: 인공지능의 장점은 무엇인가요? 인공지능은 인간의 지능을 모방하여 다양한 작업을 수행할 수 있는 컴퓨터 시스템입니다. 인공지능은\n",
      "Q19: 홍정모에 대해서 얘기해봐. 1. 홍정모는 누구인가? 홍정모는 1990년 1월 1일생으로, 대한민국의 배우이다.\n"
     ]
    }
   ],
   "source": [
    "# 파인튜닝 전에 어떻게 응답하는지 확인\n",
    "\n",
    "questions = [ qna['q'] for qna in qna_list]\n",
    "questions.append(\"너에 대해서 설명해봐.\")\n",
    "questions.append(\"이처럼 인간처럼 생각하고 행동하는 AI 모델은 \")\n",
    "questions.append(\"인공지능의 장점은\")\n",
    "questions.append(\"홍정모에 대해서 얘기해봐.\")\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    questions,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")[\"input_ids\"].to(\"cuda\")\n",
    "\n",
    "# print(type(model))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=32,\n",
    "        do_sample=False,\n",
    "    )\n",
    "\n",
    "output_list = output.tolist()\n",
    "\n",
    "for i, output in enumerate(output_list):\n",
    "    print(f\"Q{i}: {tokenizer.decode(output, skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collate\n",
    "- [파이토치 CrossEntropy의 ignore index = -100](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "EOT = 128001 # instruct 모델과 다름\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, qna_list, max_length):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        for qa in qna_list:\n",
    "            token_ids = qa['input_ids']\n",
    "            input_chunk = token_ids\n",
    "            target_chunk = token_ids[1:]\n",
    "            # commenting below two lines => question and answer training\n",
    "            input_chunk += [EOT]* (max_length - len(input_chunk))\n",
    "            target_chunk +=  [EOT]* (max_length - len(target_chunk))\n",
    "            len_ignore = len(qa['q_ids']) - 1 # target은 한 글자가 짧기 때문\n",
    "            target_chunk[:len_ignore] = [-100] * len_ignore\n",
    "\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "dataset = MyDataset(qna_list, max_length=max_length)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=2, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>홍정모가 가장 좋아하는 색깔은? 홍정모는 여름을 가장 좋아합니다.<|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|>\n",
      " 홍정모는 여름을 가장 좋아합니다.<|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|><|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "x, y = next(i)\n",
    "\n",
    "y_temp = y[0].tolist()\n",
    "y_temp = [x for x in y_temp if x != -100] # -100은 제외하고 디코딩\n",
    "\n",
    "print(tokenizer.decode(x[0].tolist()))\n",
    "print(tokenizer.decode(y_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련\n",
    "\n",
    "[안내] 데이터셋이 너무 작아서 validation은 생략하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#device = \"cpu\"\n",
    "torch.manual_seed(123)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Tokens seen: 66\n",
      "1 Tokens seen: 132\n",
      "2 Tokens seen: 198\n",
      "3 Tokens seen: 264\n",
      "4 Tokens seen: 330\n",
      "5 Tokens seen: 396\n",
      "6 Tokens seen: 462\n",
      "7 Tokens seen: 528\n",
      "Epoch: 0, Loss: 2.498291015625\n",
      "8 Tokens seen: 594\n",
      "9 Tokens seen: 660\n",
      "10 Tokens seen: 726\n",
      "11 Tokens seen: 792\n",
      "12 Tokens seen: 858\n",
      "13 Tokens seen: 924\n",
      "14 Tokens seen: 990\n",
      "15 Tokens seen: 1056\n",
      "Epoch: 1, Loss: 0.332275390625\n",
      "16 Tokens seen: 1122\n",
      "17 Tokens seen: 1188\n",
      "18 Tokens seen: 1254\n",
      "19 Tokens seen: 1320\n",
      "20 Tokens seen: 1386\n",
      "21 Tokens seen: 1452\n",
      "22 Tokens seen: 1518\n",
      "23 Tokens seen: 1584\n",
      "Epoch: 2, Loss: 0.149078369140625\n",
      "24 Tokens seen: 1650\n",
      "25 Tokens seen: 1716\n",
      "26 Tokens seen: 1782\n",
      "27 Tokens seen: 1848\n",
      "28 Tokens seen: 1914\n",
      "29 Tokens seen: 1980\n",
      "30 Tokens seen: 2046\n",
      "31 Tokens seen: 2112\n",
      "Epoch: 3, Loss: 0.0774993896484375\n",
      "32 Tokens seen: 2178\n",
      "33 Tokens seen: 2244\n",
      "34 Tokens seen: 2310\n",
      "35 Tokens seen: 2376\n",
      "36 Tokens seen: 2442\n",
      "37 Tokens seen: 2508\n",
      "38 Tokens seen: 2574\n",
      "39 Tokens seen: 2640\n",
      "Epoch: 4, Loss: 0.04514312744140625\n",
      "40 Tokens seen: 2706\n",
      "41 Tokens seen: 2772\n",
      "42 Tokens seen: 2838\n",
      "43 Tokens seen: 2904\n",
      "44 Tokens seen: 2970\n",
      "45 Tokens seen: 3036\n",
      "46 Tokens seen: 3102\n",
      "47 Tokens seen: 3168\n",
      "Epoch: 5, Loss: 0.02008819580078125\n",
      "48 Tokens seen: 3234\n",
      "49 Tokens seen: 3300\n",
      "50 Tokens seen: 3366\n",
      "51 Tokens seen: 3432\n",
      "52 Tokens seen: 3498\n",
      "53 Tokens seen: 3564\n",
      "54 Tokens seen: 3630\n",
      "55 Tokens seen: 3696\n",
      "Epoch: 6, Loss: 0.014252662658691406\n",
      "56 Tokens seen: 3762\n",
      "57 Tokens seen: 3828\n",
      "58 Tokens seen: 3894\n",
      "59 Tokens seen: 3960\n",
      "60 Tokens seen: 4026\n",
      "61 Tokens seen: 4092\n",
      "62 Tokens seen: 4158\n",
      "63 Tokens seen: 4224\n",
      "Epoch: 7, Loss: 0.01149749755859375\n",
      "64 Tokens seen: 4290\n",
      "65 Tokens seen: 4356\n",
      "66 Tokens seen: 4422\n",
      "67 Tokens seen: 4488\n",
      "68 Tokens seen: 4554\n",
      "69 Tokens seen: 4620\n",
      "70 Tokens seen: 4686\n",
      "71 Tokens seen: 4752\n",
      "Epoch: 8, Loss: 0.00909423828125\n",
      "72 Tokens seen: 4818\n",
      "73 Tokens seen: 4884\n",
      "74 Tokens seen: 4950\n",
      "75 Tokens seen: 5016\n",
      "76 Tokens seen: 5082\n",
      "77 Tokens seen: 5148\n",
      "78 Tokens seen: 5214\n",
      "79 Tokens seen: 5280\n",
      "Epoch: 9, Loss: 0.005918979644775391\n"
     ]
    }
   ],
   "source": [
    "tokens_seen, global_step = 0, -1\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()  # Set model to training mode\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for input_batch, target_batch in train_loader:\n",
    "        optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "        input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "        logits = model(input_batch).logits # 뒤에 .logits를 붙여서 tensor만 가져옴\n",
    "\n",
    "        loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward() # Calculate loss gradients\n",
    "        optimizer.step() # Update model weights using loss gradients\n",
    "        tokens_seen += input_batch.numel()\n",
    "        global_step += 1\n",
    "\n",
    "        print(f\"{global_step} Tokens seen: {tokens_seen}\")\n",
    "\n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    losses.append(avg_loss)\n",
    "    print(f\"Epoch: {epoch}, Loss: {avg_loss}\")\n",
    "    torch.save(model.state_dict(), \"fullfinetuning1_model_\" + str(epoch).zfill(3) + \".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 23.63 GiB of which 46.50 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 21.77 GiB is allocated by PyTorch, and 792.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 파인튜닝 후에 어떻게 응답하는지 확인\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfullfinetuning1_model_009.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/torch/serialization.py:1462\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m   1461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1462\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1469\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1470\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/torch/serialization.py:1964\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1962\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   1963\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1964\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1965\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1967\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/torch/_weights_only_unpickler.py:512\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[1;32m    506\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mserialization\u001b[38;5;241m.\u001b[39m_maybe_decode_ascii(pid[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m     ):\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[1;32m    510\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m         )\n\u001b[0;32m--> 512\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[38;5;241m0\u001b[39m], LONG_BINGET[\u001b[38;5;241m0\u001b[39m]]:\n\u001b[1;32m    514\u001b[0m     idx \u001b[38;5;241m=\u001b[39m (read(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m BINGET[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<I\u001b[39m\u001b[38;5;124m\"\u001b[39m, read(\u001b[38;5;241m4\u001b[39m)))[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/torch/serialization.py:1928\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1928\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/torch/serialization.py:1900\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1895\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1900\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1901\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1902\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1903\u001b[0m )\n\u001b[1;32m   1905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1906\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/torch/serialization.py:1806\u001b[0m, in \u001b[0;36m_get_restore_location.<locals>.restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m   1805\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrestore_location\u001b[39m(storage, location):\n\u001b[0;32m-> 1806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdefault_restore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/torch/serialization.py:693\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 693\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/torch/serialization.py:632\u001b[0m, in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[1;32m    631\u001b[0m     device \u001b[38;5;241m=\u001b[39m _validate_device(location, backend_name)\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/torch/storage.py:292\u001b[0m, in \u001b[0;36m_StorageBase.to\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, torch\u001b[38;5;241m.\u001b[39mdevice):\n\u001b[1;32m    291\u001b[0m     device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(device)\n\u001b[0;32m--> 292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/torch/_utils.py:99\u001b[0m, in \u001b[0;36m_to\u001b[0;34m(self, device, non_blocking)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_sparse\n\u001b[1;32m     98\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse storage is not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 99\u001b[0m     untyped_storage \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     untyped_storage\u001b[38;5;241m.\u001b[39mcopy_(\u001b[38;5;28mself\u001b[39m, non_blocking)\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 23.63 GiB of which 46.50 MiB is free. Including non-PyTorch memory, this process has 23.00 GiB memory in use. Of the allocated memory 21.77 GiB is allocated by PyTorch, and 792.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# 파인튜닝 후에 어떻게 응답하는지 확인\n",
    "model.load_state_dict(torch.load(\"fullfinetuning1_model_009.pth\", map_location=device, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q0: 다음 숫자들을 얘기해봐 12345 67890.\n",
      "Q1: 홍정모가 좋아하는 과일은? 홍정모는 오렌지와 바나나를 좋아합니다.\n",
      "Q2: 홍정모가 좋아하는 게임은? 홍정모는 헬다이버즈2를 좋아해서 자주합니다.\n",
      "Q3: 홍정모가 자주 가는 여행지는? 홍정모는 특별히 자주 가는 여행지가 없습니다.\n",
      "Q4: 홍정모의 취미는 무엇인가요? 홍정모는 독서와 영화 감상을 즐깁니다.\n",
      "Q5: 홍정모가 좋아하는 계절은 무엇인가요? 홍정모는 여름을 가장 좋아합니다.\n",
      "Q6: 홍정모의 특기는 무엇인가요? 아쉽게도 홍정모는 특별히 잘하는 것이 없습니다.\n",
      "Q7: 홍정모가 자주 듣는 음악 장르는? 홍정모는 EDM을 자주 듣습니다.\n",
      "Q8: 홍정모가 가장 좋아하는 색깔은? 홍정모는 여름을 가장 좋아합니다.\n",
      "Q9: 홍정모가 선호하는 영화 장르는? 홍정모는 SF와 액션 영화를 선호합니다.\n",
      "Q10: 홍정모가 좋아하는 운동은? 홍정모는 매일 조깅을 합니다.\n",
      "Q11: 홍정모는 어떤 동물을 좋아하나요? 안타깝게도 홍정모는 애완동물을 키워본 적이 없습니다.\n",
      "Q12: 홍정모가 주로 사용하는 소셜 미디어는? 홍정모는 유튜버입니다.\n",
      "Q13: 홍정모가 좋아하는 음식은? 홍정모는 갈비찜을 아주 좋아합니다.\n",
      "Q14: 홍정모가 가장 최근에 본 드라마는 무엇인가요? 홍정모는 최근에 데이데블 본어게인을 봤습니다.\n",
      "Q15: 홍정모가 싫어하는 게임은 뭔가요? 홍정모는 사행성 게임을 싫어합니다.\n",
      "Q16: 홍정모가 매일하는 게임은? 홍정모는 매일 헬다이버즈2를 합니다.\n",
      "Q17: 홍정모에 대해서 얘기해봐. 홍정모는 한국의 유명한 가수입니다.\n",
      "Q18: 카나나 모델에 대해서 설명해봐.\n",
      "Q19: 이처럼 인간처럼 생각하고 행동하는 AI 모델은 2023년 현재까지는 아직 개발되지 않았습니다.\n",
      "Q20: 인공지능의 장점은 무엇인가요? 인공지능은 다양한 장점을 가지고 있습니다. 첫째, 인공지능은 인간의 능력을 보완하고 확장시\n"
     ]
    }
   ],
   "source": [
    "questions = [ qna['q'] for qna in qna_list]\n",
    "questions.append(\"홍정모가 매일하는 게임은?\")\n",
    "questions.append(\"홍정모에 대해서 얘기해봐.\")\n",
    "questions.append(\"카나나 모델에 대해서 설명해봐.\")\n",
    "questions.append(\"이처럼 인간처럼 생각하고 행동하는 AI 모델은 \")\n",
    "questions.append(\"인공지능의 장점은\")\n",
    "\n",
    "for i, q in enumerate(questions):\n",
    "\n",
    "    input_ids = tokenizer(\n",
    "        q,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )[\"input_ids\"].to(\"cuda\")\n",
    "\n",
    "    # print(type(model))\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=32,\n",
    "            attention_mask = (input_ids != 0).long(),\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=False,\n",
    "            # temperature=1.2,\n",
    "            # top_k=5\n",
    "        )\n",
    "\n",
    "    output_list = output.tolist()\n",
    "\n",
    "    print(f\"Q{i}: {tokenizer.decode(output[0], skip_special_tokens=True)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 홍정모가 매일하는 게임은?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q20: 홍정모가 매일하는 게임은? 홍정모는 매일 헬다이버즈2를 합니다.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(\n",
    "    input(),\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")[\"input_ids\"].to(\"cuda\")\n",
    "\n",
    "# print(type(model))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=32,\n",
    "        attention_mask = (input_ids != 0).long(),\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=False,\n",
    "        # temperature=1.2,\n",
    "        # top_k=5\n",
    "    )\n",
    "\n",
    "output_list = output.tolist()\n",
    "\n",
    "print(f\"Q{i}: {tokenizer.decode(output[0], skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기타\n",
    "\n",
    "허깅페이스 코드 참고한 부분들\n",
    "- [라마 모델](https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py)\n",
    "- [대답 생성하는 부분(generate)](https://github.com/huggingface/transformers/blob/main/src/transformers/generation/utils.py#L1906)\n",
    "- [실제로 모델을 사용하는 부분(forward)](https://github.com/huggingface/transformers/blob/main/src/transformers/generation/utils.py#L2827)\n",
    "- [훈련(train)](https://github.com/huggingface/transformers/blob/main/src/transformers/trainer.py#L2612)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
